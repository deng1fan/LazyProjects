##########################################################################
#
#
#        ______                  __   ___  __
#        |  _  \                 \ \ / (_)/ _|
#        | | | |___ _ __   __ _   \ V / _| |_ __ _ _ __
#        | | | / _ \ '_ \ / _` |   \ / | |  _/ _` | '_ \
#        | |/ /  __/ | | | (_| |   | | | | || (_| | | | |
#        |___/ \___|_| |_|\__, |   \_/ |_|_| \__,_|_| |_|
#                          __/ |
#                         |___/
#
#
# Github: https://github.com/D-Yifan
# Zhi hu: https://www.zhihu.com/people/deng_yifan
#
##########################################################################

"""
Author: Deng Yifan 553192215@qq.com
Date: 2022-08-25 08:27:32
LastEditors: Deng Yifan 553192215@qq.com
LastEditTime: 2022-09-19 07:23:23
FilePath: /faith_dial/run.py
Description: 

Copyright (c) 2022 by Deng Yifan 553192215@qq.com, All Rights Reserved. 
"""
# -*- coding: utf-8 -*-
from omegaconf import DictConfig
import os
import yaml
from general_files.trainer.processor import get_trainer_processor
from general_files.utils.others.data_processor.processor import get_data_processor
from omegaconf import DictConfig
import importlib
from general_files.utils.common_util import (
    send_msg_to_DingTalk_and_wx,
    Result,
    get_logger,
    check_config,
    print_config,
    set_config_gpus,
    init_context,
    dingtalk_sender_and_wx,
    print_error_info,
    print_generated_dialogs,
    init_comet_experiment,
    seed_everything,
    RedisClient,
    print_start_image,
)
from general_files.utils.model_util import (
    get_eval_metrics,
    generate_sentences,
    predict_labels,
)
from general_files.utils.data_util import (
    concatenate_multi_datasets,
    print_sample_data,
    get_custom_test_output,
)
import sys
import torch
import time
from datasets import Dataset

log = get_logger(__name__)

with open("./configs/default_config.yaml", "r") as file:
    global_config = DictConfig(yaml.safe_load(file.read()))


def main(config: DictConfig) -> float:

    print_start_image()

    ###############################################
    # è®¾ç½®éšæœºç§å­
    ###############################################
    log.info(f"è®¾ç½® seed ä¸º:  {config.seed}")
    seed_everything(config.seed)

    ###############################################
    # æ£€æŸ¥é…ç½®
    ###############################################
    config = check_config(config)

    ###############################################
    # æ‰“å°é…ç½®ä¿¡æ¯
    ###############################################
    if config.print_config:
        print_config(config, resolve=True)

    ###############################################
    # ç™»è®°è¿›ç¨‹ä¿¡æ¯
    ###############################################
    redis_client = RedisClient()
    task_id = redis_client.register_process(config)
    config.task_id = task_id

    if config.logger == "comet":
        test_results, config = train_or_test_with_DingTalk(
            config)
    else:
        test_results, config = train_or_test(config)

    redis_client.deregister_process(config)

    return 0


@dingtalk_sender_and_wx(
    webhook_url=global_config.dingding_web_hook,
    secret=global_config.dingding_secret,
)
def train_or_test_with_DingTalk(config):
    return train_or_test(config)


def train_or_test(config):

    test_output = None
    test_results = Result()
    if config.get("script_path"):
        ###############################################
        # è‡ªåŠ¨é€‰æ‹© GPU
        ###############################################
        config = set_config_gpus(config)

        ###############################################
        # ç¬¬ä¸‰æ–¹æ¨¡å‹è¯„ä¼°
        ###############################################
        test_output = get_custom_test_output(config)
        log.info("è¯„ä¼°æ¨¡å‹ï¼")

        if config.eval_metrics is not None:
            test_results = get_eval_metrics(test_output, config)
        return test_results, config

    ###############################################
    # åŠ è½½æµ‹è¯•è¾“å‡ºç»“æœç¼“å­˜
    ###############################################
    log.info("åˆå§‹åŒ–è®­ç»ƒã€æµ‹è¯•ç­‰æ‰€éœ€ç¯å¢ƒ")
    if config.stage == "test":
        # åœ¨æµ‹è¯•é˜¶æ®µï¼Œå¦‚æœæœ‰ä¹‹å‰çš„ç”Ÿæˆç¼“å­˜ï¼Œåˆ™ç›´æ¥è¯»å–
        test_output_path = config.ckpt_path
        if ".ckpt" in test_output_path:
            test_output_path = "/".join(test_output_path.split("/")[:-1])
        if os.path.exists(test_output_path + "/test_output.csv"):
            log.info(f"å‘ç°æµ‹è¯•è¾“å‡ºç»“æœç¼“å­˜ï¼Œå‡†å¤‡åŠ è½½...: {test_output_path}")
            # test_output = read_by(
            #     test_output_path + "/test_output.csv", data_name="æµ‹è¯•è¾“å‡º")
            test_output = Dataset.from_csv(test_output_path + "/test_output.csv")
        if config.ckpt_path:
            # å¾®è°ƒã€æµ‹è¯•çš„åˆ†è¯å™¨åŠ è½½
            tokenizer_module_path = "general_files.modules.tokenizer"
            tokenizer_module = importlib.import_module(tokenizer_module_path)
            tokenizer = getattr(tokenizer_module, "Tokenizer")
            tokenizer = tokenizer(config=config)



    if test_output is None:

        ###############################################
        # åŠ è½½æ•°æ®é›†ã€æ¨¡å‹ã€åˆ†è¯å™¨
        ###############################################
        # è®­ç»ƒæˆ–å¾®è°ƒï¼Œæˆ–è€…æµ‹è¯•æ—¶æ²¡æœ‰ç¼“å­˜ï¼Œéœ€è¦é‡æ–°åŠ è½½æ•°æ®
        (model,
         tokenizer,
         train_data_tokenized,
         valid_data_tokenized,
         test_data_tokenized,
         raw_data,
         ) = init_context(config)

    ###############################################
    # è‡ªåŠ¨é€‰æ‹© GPU
    ###############################################
    config = set_config_gpus(config)

    
    ###############################################
    # åˆå§‹åŒ– Comet
    ###############################################
    experiment = init_comet_experiment(config)

    try:
        if test_output is None:
            print_sample_data(
                tokenizer,
                [train_data_tokenized, valid_data_tokenized, test_data_tokenized],
                ["Train data", "Valid data", "Test data"],
                config=config,
                experiment=experiment,
            )

        ###############################################
        # æ¨¡å‹è®­ç»ƒ
        ###############################################
        if config.stage in ["train", "finetune", "pretrain"]:
            # éæµ‹è¯•é˜¶æ®µ
            log.info(f"åˆå§‹åŒ– Trainer...")
            trainer_processor = get_trainer_processor(config)
            trainer = trainer_processor(
                config=config,
                model=model,
                train_dataset=train_data_tokenized,
                eval_dataset=valid_data_tokenized,
                tokenizer=tokenizer,
                experiment=experiment,
            )

            log.info(f"è®­ç»ƒå¼€å§‹ï¼")
            
            # å‘é€é’‰é’‰é€šçŸ¥
            try:
                send_msg_to_DingTalk_and_wx(f"{config.comet_name} å¼€å§‹è®­ç»ƒï¼ğŸƒğŸ»ğŸƒğŸ»ğŸƒğŸ»", config)
            except Exception as e:
                print_error_info(e)
                log.info(f"å‘é€é’‰é’‰é€šçŸ¥å¤±è´¥: {e}")
                
            model = trainer.train()

        ###############################################
        # ç”Ÿæˆæµ‹è¯•è¾“å‡ºç»“æœç¼“å­˜
        ###############################################
        if test_output is None:

            ###############################################
            # æ¨¡å‹æµ‹è¯•
            ###############################################
            model.eval()
            model = model.to(config.default_device)

            log.info(f"ä½¿ç”¨æœ€ä¼˜æ¨¡å‹è¿›è¡Œé¢„æµ‹/ç”Ÿæˆï¼")
            if config.data_mode == "classification":
                test_output = test_data_tokenized.map(
                    lambda batch: {
                        "generated": predict_labels(model, batch, tokenizer, config=config)
                    },
                    batched=True,
                    batch_size=config.test_batch_size,
                    desc="æ­£åœ¨é¢„æµ‹åˆ†ç±»æ ‡ç­¾",
                )
            else:
                test_output = test_data_tokenized.map(
                    lambda batch: {
                        "generated": generate_sentences(
                            model, batch, tokenizer, config=config
                        )
                    },
                    batched=True,
                    batch_size=config.test_batch_size,
                    desc="æ­£åœ¨ç”Ÿæˆ",
                )

            if config.eval_bad_case_analysis:
                test_output = concatenate_multi_datasets(
                    test_output, raw_data[-2])
            else:
                test_output = concatenate_multi_datasets(
                    test_output, raw_data[-1])

            if config.data_mode != "classification":
                test_output = test_output.map(
                    lambda batch: {
                        "generated_seqs": batch["generated"]["seqs"],
                        "generated_seqs_with_special_tokens": batch["generated"][
                            "seqs_with_special_tokens"
                        ],
                    },
                    desc="ç”Ÿæˆè¯­å¥å­—å…¸å±•å¼€æ˜ å°„",
                )
                test_output = test_output.remove_columns(["generated"])


        ###############################################
        # æ¸…ç©º cuda ç¼“å­˜
        ###############################################
        if config.stage in ["train", "finetune", "pretrain"]:
            print(torch.cuda.memory.memory_summary())
            log.info("æ¸…ç©º cuda ç¼“å­˜")

            model = model.to("cpu")
            torch.cuda.empty_cache()
            time.sleep(5)
        
        print(torch.cuda.memory.memory_summary())

        ###############################################
        # å°†æ‰€æœ‰è¾“å‡ºåˆ—åæ ‡å‡†åŒ–ä»¥ä½¿ç”¨ç»Ÿä¸€çš„è¯„ä»·æŒ‡æ ‡å‡½æ•°
        ###############################################
        data_processor = get_data_processor(config, tokenizer)
        test_output = data_processor.map_column(test_output)
        if config.data_mode != "classification":
            # ä¿å­˜æµ‹è¯•ç”Ÿæˆè¯­å¥æ–¹ä¾¿ä»¥åæµ‹è¯•
            print_generated_dialogs(
                test_output, mode=config.data_mode, config=config, experiment=experiment)

        ###############################################
        # æ¨¡å‹è¯„ä¼°
        ###############################################
        log.info("è¯„ä¼°æ¨¡å‹ï¼")
        if config.eval_metrics is not None:
            test_results = get_eval_metrics(test_output, config)

        ###############################################
        # æ‰“å° ckpt å­˜å‚¨ä¿¡æ¯
        ###############################################
        if not config.fast_run:
            log.info(f"å¦‚æœè¦ä½¿ç”¨æ­¤æ¬¡æ¨¡å‹ï¼Œè¯·è®¾ç½® ckpt_identifier ä¸º: ")
            log.info(f"{config.task_full_name}")
            log.info(f"è¿è¡Œç»“æœä¿å­˜åœ¨ï¼š")
            log.info(f"{config.result_path}")

        ###############################################
        # åˆ é™¤Redisçš„Gpuå ç”¨è®°å½•
        ###############################################
        if config.task_id:
            redis_client = RedisClient()
            redis_client.deregister_gpus(config)
            
            
        tmux_session = ""
        for arg in sys.argv:
            if "tmux_session" in arg:
                tmux_session = arg.replace("+tmux_session=", "")

        test_results.add(
            run_name=config.comet_name,
            comet_name=config.comet_name,
            memo=config.memo,
        )
        if tmux_session != "":
            test_results.add(tmux_session=tmux_session)

        ###############################################
        # æ›´æ–° Comet ä¿¡æ¯
        ###############################################
        if experiment:
            if test_results is not None:
                for key, value in test_results.items():
                    if key in ["run_name", "comet_name", "memo", "tmux_session"]:
                        continue
                    experiment.log_metric(key, value)
                experiment.add_tag("Metric")
            if config.eval_bad_case_analysis:
                experiment.add_tag("Bad Case Analysis")
            experiment.add_tag("Finish")

    except KeyboardInterrupt as e:
        print("ç¨‹åºå—åˆ°äººä¸ºä¸­æ–­ï¼")
        if config.get("logger") == "comet" and experiment:
            experiment.add_tag("KeyboardInterrupt")
            experiment.set_name(config.comet_name + "  Interrupt!")
            raise e
    except RuntimeError as e:
        print_error_info(e)
        if config.get("logger") == "comet" and experiment:
            experiment.add_tag("Crashed")
            experiment.set_name(config.comet_name + "  Error!")
            raise Exception(e)
    except Exception as e:
        print_error_info(e)
        if config.get("logger") == "comet" and experiment:
            experiment.add_tag("Crashed")
            experiment.set_name(config.comet_name + "  Error!")
            raise e
    finally:
        if config.get("logger") == "comet" and experiment:
            experiment.end()
    return test_results, config
